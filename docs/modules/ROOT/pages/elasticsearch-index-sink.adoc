// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT

= image:kamelets/elasticsearch-index-sink.svg[] ElasticSearch Index Sink

*Provided by: "Red Hat"*

Stores JSON-formatted data into ElasticSearch.

The input data must be formatted in JSON according to the requirements of the index. 

If you specify the `certificate` property, you must base64 encode it before you pass it as a parameter.

In the header, you can set the following properties:

- `indexId` / `ce-indexid`: The index ID for ElasticSearch.

- `indexName` / `ce-indexname`: The index name for ElasticSearch.

If you do not set a property in the header, the Kamelet uses the exchange ID for the index setting.

== Configuration Options

The following table summarizes the configuration options available for the `elasticsearch-index-sink` Kamelet:
[width="100%",cols="2,^2,3,^2,^2,^3",options="header"]
|===
| Property| Name| Description| Type| Default| Example
| *clusterName {empty}* *| ElasticSearch Cluster Name| The name of the ElasticSearch cluster.| string| | `"quickstart"`
| *hostAddresses {empty}* *| Host Addresses| A comma-separated list of remote transport addresses in `ip:port format`.| string| | `"quickstart-es-http:9200"`
| certificate| Certificate| The Certificate for accessing the Elasticsearch cluster. You must encode this value in base64.| string| | 
| enableSSL| Enable SSL| Specifies to connect by using SSL.| boolean| `true`| 
| indexName| Index in ElasticSearch| The name of the ElasticSearch index.| string| | `"data"`
| password| Password| The password to connect to ElasticSearch.| string| | 
| user| Username| The username to connect to ElasticSearch.| string| | 
|===

NOTE: Fields marked with an asterisk ({empty}*) are mandatory.


== Dependencies

At runtime, the `elasticsearch-index-sink` Kamelet relies upon the presence of the following dependencies:

- camel:core
- camel:jackson
- camel:kamelet
- camel:elasticsearch
- camel:gson
- camel:bean 

== Usage

This section describes how you can use the `elasticsearch-index-sink`.

=== Knative Sink

You can use the `elasticsearch-index-sink` Kamelet as a Knative sink by binding it to a Knative object.

.elasticsearch-index-sink-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: elasticsearch-index-sink-binding
spec:
  source:
    ref:
      kind: Channel
      apiVersion: messaging.knative.dev/v1
      name: mychannel
  sink:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: elasticsearch-index-sink
    properties:
      clusterName: "quickstart"
      hostAddresses: "quickstart-es-http:9200"
  
----

==== *Prerequisite*

Make sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `elasticsearch-index-sink-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the sink by using the following command:
+
[source,shell]
----
oc apply -f elasticsearch-index-sink-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the sink by using the following command:

[source,shell]
----
kamel bind channel:mychannel elasticsearch-index-sink -p "sink.clusterName=quickstart" -p "sink.hostAddresses=quickstart-es-http:9200"
----

This command creates the KameletBinding in the current namespace on the cluster.

=== Kafka Sink

You can use the `elasticsearch-index-sink` Kamelet as a Kafka sink by binding it to a Kafka topic.

.elasticsearch-index-sink-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: elasticsearch-index-sink-binding
spec:
  source:
    ref:
      kind: KafkaTopic
      apiVersion: kafka.strimzi.io/v1beta1
      name: my-topic
  sink:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: elasticsearch-index-sink
    properties:
      clusterName: "quickstart"
      hostAddresses: "quickstart-es-http:9200"
  
----

==== *Prerequisites*

Ensure that you've installed the *AMQ Streams* operator in your OpenShift cluster and created a topic named `my-topic` in the current namespace.
Make also sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `elasticsearch-index-sink-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the sink by using the following command:
+
[source,shell]
----
oc apply -f elasticsearch-index-sink-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the sink by using the following command:

[source,shell]
----
kamel bind kafka.strimzi.io/v1beta1:KafkaTopic:my-topic elasticsearch-index-sink -p "sink.clusterName=quickstart" -p "sink.hostAddresses=quickstart-es-http:9200"
----

This command creates the KameletBinding in the current namespace on the cluster.

== Kamelet source file

https://github.com/openshift-integration/kamelet-catalog/blob/main/elasticsearch-index-sink.kamelet.yaml

// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT
