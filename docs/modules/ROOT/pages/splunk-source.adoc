// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT

= image:kamelets/splunk-source.svg[] Splunk Source

*Provided by: "Red Hat"*

Retrieve data from Splunk and outputs in json format.

For the fields accepting time specifiers like `earliestTime`, it accepts a wide variety of formats, please check https://docs.splunk.com/Documentation/Splunk/9.0.0/Search/Specifytimemodifiersinyoursearch[Splunk documentation] for more information.

== Configuration Options

The following table summarizes the configuration options available for the `splunk-source` Kamelet:
[width="100%",cols="2,^2,3,^2,^2,^3",options="header"]
|===
| Property| Name| Description| Type| Default| Example
| *initEarliestTime {empty}* *| Init Earliest Time| Initial start offset of the first search.| string| | `"05/17/22 08:35:46:456"`
| *password {empty}* *| Password| The password to authenticate to Splunk Server.| string| | 
| *query {empty}* *| Query| The Splunk query to run.| string| | 
| *serverHostname {empty}* *| Splunk Server Address| The address of your Splunk server.| string| | `"my_server_splunk.com"`
| *username {empty}* *| Username| The username to authenticate to Splunk Server.| string| | 
| app| Splunk App| The app name in Splunk.| string| | 
| connectionTimeout| Connection Timeout| Timeout in milliseconds when connecting to Splunk server| integer| | 
| count| Count| The maximum number of entities to return.| integer| | 
| delay| Delay| The number of milliseconds before the next poll.| integer| | 
| earliestTime| Earliest Time| Earliest time of the search time window.| string| | `"05/17/22 08:35:46:456"`
| index| Index| Splunk index to write to.| string| | 
| latestTime| Latest Time| Latest time of the search time window.| string| | `"05/17/22 08:35:46:456"`
| protocol| Protocol| Connection Protocol to Splunk server.| string| `"https"`| 
| repeat| Repeat| The maximum number of fires.| integer| | 
| serverPort| Splunk Server Port| The address of your Splunk server.| integer| `8089`| 
| source| Source| The source named field of the data.| string| | 
| sourceType| Source Type| The source named field of the data.| string| | 
|===

NOTE: Fields marked with an asterisk ({empty}*) are mandatory.


== Dependencies

At runtime, the `splunk-source` Kamelet relies upon the presence of the following dependencies:

- camel:jackson
- camel:core
- camel:splunk
- camel:kamelet
- mvn:com.fasterxml.jackson.datatype:jackson-datatype-joda:2.12.5 

== Usage

This section describes how you can use the `splunk-source`.

=== Knative Source

You can use the `splunk-source` Kamelet as a Knative source by binding it to a Knative object.

.splunk-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: splunk-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: splunk-source
    properties:
      initEarliestTime: "05/17/22 08:35:46:456"
      password: "The Password"
      query: "The Query"
      serverHostname: "my_server_splunk.com"
      username: "The Username"
  sink:
    ref:
      kind: Channel
      apiVersion: messaging.knative.dev/v1
      name: mychannel
  
----

==== *Prerequisite*

Make sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `splunk-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f splunk-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind splunk-source -p "source.initEarliestTime=05/17/22 08:35:46:456" -p "source.password=The Password" -p "source.query=The Query" -p "source.serverHostname=my_server_splunk.com" -p "source.username=The Username" channel:mychannel
----

This command creates the KameletBinding in the current namespace on the cluster.

=== Kafka Source

You can use the `splunk-source` Kamelet as a Kafka source by binding it to a Kafka topic.

.splunk-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: splunk-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: splunk-source
    properties:
      initEarliestTime: "05/17/22 08:35:46:456"
      password: "The Password"
      query: "The Query"
      serverHostname: "my_server_splunk.com"
      username: "The Username"
  sink:
    ref:
      kind: KafkaTopic
      apiVersion: kafka.strimzi.io/v1beta1
      name: my-topic
  
----

==== *Prerequisites*

Ensure that you've installed the *AMQ Streams* operator in your OpenShift cluster and created a topic named `my-topic` in the current namespace.
Make also sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `splunk-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f splunk-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind splunk-source -p "source.initEarliestTime=05/17/22 08:35:46:456" -p "source.password=The Password" -p "source.query=The Query" -p "source.serverHostname=my_server_splunk.com" -p "source.username=The Username" kafka.strimzi.io/v1beta1:KafkaTopic:my-topic
----

This command creates the KameletBinding in the current namespace on the cluster.

== Kamelet source file

https://github.com/openshift-integration/kamelet-catalog/blob/main/splunk-source.kamelet.yaml

// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT
