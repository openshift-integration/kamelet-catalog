// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT

= image:kamelets/kafka-batch-ssl-source.svg[] Kafka Batch SSL Source

*Provided by: "Red Hat"*

Receive data from Kafka topics in batch with SSL/TLS support and commit them manually through KafkaManualCommit or automatically.

== Configuration Options

The following table summarizes the configuration options available for the `kafka-batch-ssl-source` Kamelet:
[width="100%",cols="2,^2,3,^2,^2,^3",options="header"]
|===
| Property| Name| Description| Type| Default| Example
| *bootstrapServers {empty}* *| Bootstrap Servers| Comma separated list of Kafka Broker URLs| string| | 
| *sslKeyPassword {empty}* *| SSL Key Password| The password of the private key in the key store file.| string| | 
| *sslTruststoreLocation {empty}* *| SSL Truststore Location| The location of the trust store file.| string| | 
| *topic {empty}* *| Topic Names| Comma separated list of Kafka topic names| string| | 
| allowManualCommit| Allow Manual Commit| Whether to allow doing manual commits| boolean| `false`| 
| autoCommitEnable| Auto Commit Enable| If true, periodically commit to ZooKeeper the offset of messages already fetched by the consumer| boolean| `true`| 
| autoOffsetReset| Auto Offset Reset| What to do when there is no initial offset. There are 3 enums and the value can be one of latest, earliest, none| string| `"latest"`| 
| batchSize| Batch Dimension| The maximum number of records returned in a single call to poll()| int| `500`| 
| consumerGroup| Consumer Group| A string that uniquely identifies the group of consumers to which this source belongs| string| | `"my-group-id"`
| deserializeHeaders| Automatically Deserialize Headers| When enabled the Kamelet source will deserialize all message headers to String representation.| boolean| `true`| 
| maxPollIntervalMs| Max Poll Interval| The maximum delay between invocations of poll() when using consumer group management| int| | 
| pollOnError| Poll On Error Behavior| What to do if kafka threw an exception while polling for new messages. There are 5 enums and the value can be one of DISCARD, ERROR_HANDLER, RECONNECT, RETRY, STOP| string| `"ERROR_HANDLER"`| 
| pollTimeout| Poll Timeout Interval| The timeout used when polling the KafkaConsumer| int| `5000`| 
| saslJaasConfig| JAAS Configuration| Java Authentication and Authorization Service (JAAS) for Simple Authentication and Security Layer (SASL) configuration.| string| | 
| saslMechanism| SASL Mechanism| The Simple Authentication and Security Layer (SASL) Mechanism used.| string| `"GSSAPI"`| 
| securityProtocol| Security Protocol| Protocol used to communicate with brokers. SASL_PLAINTEXT, PLAINTEXT, SASL_SSL and SSL are supported| string| `"SSL"`| 
| sslEnabledProtocols| SSL Enabled Protocols| The list of protocols enabled for SSL connections. TLSv1.2, TLSv1.1 and TLSv1 are enabled by default.| string| `"TLSv1.2,TLSv1.1,TLSv1"`| 
| sslEndpointAlgorithm| SSL Endpoint Algorithm| The endpoint identification algorithm to validate server hostname using server certificate. Use none or false to disable server hostname verification.| string| `"https"`| 
| sslKeystoreLocation| SSL Keystore Location| The location of the key store file. This is optional for client and can be used for two-way authentication for client.| string| | 
| sslKeystorePassword| SSL Keystore Password| The store password for the key store file.This is optional for client and only needed if ssl.keystore.location is configured.| string| | 
| sslProtocol| SSL Protocol| The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported in older JVMs, but their usage is discouraged due to known security vulnerabilities.| string| `"TLSv1.2"`| 
|===

NOTE: Fields marked with an asterisk ({empty}*) are mandatory.


== Dependencies

At runtime, the `kafka-batch-ssl-source` Kamelet relies upon the presence of the following dependencies:

- github:openshift-integration.kamelet-catalog:camel-kamelets-utils:2.2.0-SNAPSHOT
- camel:core
- camel:kafka
- camel:kamelet 

== Usage

This section describes how you can use the `kafka-batch-ssl-source`.

=== Knative Source

You can use the `kafka-batch-ssl-source` Kamelet as a Knative source by binding it to a Knative object.

.kafka-batch-ssl-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: kafka-batch-ssl-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: kafka-batch-ssl-source
    properties:
      bootstrapServers: "The Bootstrap Servers"
      sslKeyPassword: "The SSL Key Password"
      sslTruststoreLocation: "The SSL Truststore Location"
      topic: "The Topic Names"
  sink:
    ref:
      kind: Channel
      apiVersion: messaging.knative.dev/v1
      name: mychannel
  
----

==== *Prerequisite*

Make sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `kafka-batch-ssl-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f kafka-batch-ssl-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind kafka-batch-ssl-source -p "source.bootstrapServers=The Bootstrap Servers" -p "source.sslKeyPassword=The SSL Key Password" -p "source.sslTruststoreLocation=The SSL Truststore Location" -p "source.topic=The Topic Names" channel:mychannel
----

This command creates the KameletBinding in the current namespace on the cluster.

=== Kafka Source

You can use the `kafka-batch-ssl-source` Kamelet as a Kafka source by binding it to a Kafka topic.

.kafka-batch-ssl-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: kafka-batch-ssl-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: kafka-batch-ssl-source
    properties:
      bootstrapServers: "The Bootstrap Servers"
      sslKeyPassword: "The SSL Key Password"
      sslTruststoreLocation: "The SSL Truststore Location"
      topic: "The Topic Names"
  sink:
    ref:
      kind: KafkaTopic
      apiVersion: kafka.strimzi.io/v1beta1
      name: my-topic
  
----

==== *Prerequisites*

Ensure that you've installed the *AMQ Streams* operator in your OpenShift cluster and created a topic named `my-topic` in the current namespace.
Make also sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `kafka-batch-ssl-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f kafka-batch-ssl-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind kafka-batch-ssl-source -p "source.bootstrapServers=The Bootstrap Servers" -p "source.sslKeyPassword=The SSL Key Password" -p "source.sslTruststoreLocation=The SSL Truststore Location" -p "source.topic=The Topic Names" kafka.strimzi.io/v1beta1:KafkaTopic:my-topic
----

This command creates the KameletBinding in the current namespace on the cluster.

== Kamelet source file

https://github.com/openshift-integration/kamelet-catalog/blob/main/kafka-batch-ssl-source.kamelet.yaml

// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT
