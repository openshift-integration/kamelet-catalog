// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT

= image:kamelets/kafka-batch-source.svg[] Kafka Batch Source

*Provided by: "Red Hat"*

Receive data from Kafka topics in batch through Plain Login Module and commit them manually through KafkaManualCommit.

== Configuration Options

The following table summarizes the configuration options available for the `kafka-batch-source` Kamelet:
[width="100%",cols="2,^2,3,^2,^2,^3",options="header"]
|===
| Property| Name| Description| Type| Default| Example
| *bootstrapServers {empty}* *| Bootstrap Servers| Comma separated list of Kafka Broker URLs| string| | 
| *password {empty}* *| Password| Password to authenticate to kafka| string| | 
| *topic {empty}* *| Topic Names| Comma separated list of Kafka topic names| string| | 
| *user {empty}* *| Username| Username to authenticate to Kafka| string| | 
| allowManualCommit| Allow Manual Commit| Whether to allow doing manual commits| boolean| `false`| 
| autoCommitEnable| Auto Commit Enable| If true, periodically commit to ZooKeeper the offset of messages already fetched by the consumer| boolean| `true`| 
| autoOffsetReset| Auto Offset Reset| What to do when there is no initial offset. There are 3 enums and the value can be one of latest, earliest, none| string| `"latest"`| 
| batchSize| Batch Dimension| The maximum number of records returned in a single call to poll()| int| `500`| 
| consumerGroup| Consumer Group| A string that uniquely identifies the group of consumers to which this source belongs| string| | `"my-group-id"`
| deserializeHeaders| Automatically Deserialize Headers| When enabled the Kamelet source will deserialize all message headers to String representation.| boolean| `true`| 
| maxPollIntervalMs| Max Poll Interval| The maximum delay between invocations of poll() when using consumer group management| int| | 
| pollOnError| Poll On Error Behavior| What to do if kafka threw an exception while polling for new messages. There are 5 enums and the value can be one of DISCARD, ERROR_HANDLER, RECONNECT, RETRY, STOP| string| `"ERROR_HANDLER"`| 
| pollTimeout| Poll Timeout Interval| The timeout used when polling the KafkaConsumer| int| `5000`| 
| saslMechanism| SASL Mechanism| The Simple Authentication and Security Layer (SASL) Mechanism used.| string| `"PLAIN"`| 
| securityProtocol| Security Protocol| Protocol used to communicate with brokers. SASL_PLAINTEXT, PLAINTEXT, SASL_SSL and SSL are supported| string| `"SASL_SSL"`| 
|===

NOTE: Fields marked with an asterisk ({empty}*) are mandatory.


== Dependencies

At runtime, the `kafka-batch-source` Kamelet relies upon the presence of the following dependencies:

- github:openshift-integration.kamelet-catalog:camel-kamelets-utils:2.2.0-SNAPSHOT
- camel:core
- camel:kafka
- camel:kamelet 

== Usage

This section describes how you can use the `kafka-batch-source`.

=== Knative Source

You can use the `kafka-batch-source` Kamelet as a Knative source by binding it to a Knative object.

.kafka-batch-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: kafka-batch-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: kafka-batch-source
    properties:
      bootstrapServers: "The Bootstrap Servers"
      password: "The Password"
      topic: "The Topic Names"
      user: "The Username"
  sink:
    ref:
      kind: Channel
      apiVersion: messaging.knative.dev/v1
      name: mychannel
  
----

==== *Prerequisite*

Make sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `kafka-batch-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f kafka-batch-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind kafka-batch-source -p "source.bootstrapServers=The Bootstrap Servers" -p "source.password=The Password" -p "source.topic=The Topic Names" -p "source.user=The Username" channel:mychannel
----

This command creates the KameletBinding in the current namespace on the cluster.

=== Kafka Source

You can use the `kafka-batch-source` Kamelet as a Kafka source by binding it to a Kafka topic.

.kafka-batch-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: KameletBinding
metadata:
  name: kafka-batch-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: kafka-batch-source
    properties:
      bootstrapServers: "The Bootstrap Servers"
      password: "The Password"
      topic: "The Topic Names"
      user: "The Username"
  sink:
    ref:
      kind: KafkaTopic
      apiVersion: kafka.strimzi.io/v1beta1
      name: my-topic
  
----

==== *Prerequisites*

Ensure that you've installed the *AMQ Streams* operator in your OpenShift cluster and created a topic named `my-topic` in the current namespace.
Make also sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `kafka-batch-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f kafka-batch-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind kafka-batch-source -p "source.bootstrapServers=The Bootstrap Servers" -p "source.password=The Password" -p "source.topic=The Topic Names" -p "source.user=The Username" kafka.strimzi.io/v1beta1:KafkaTopic:my-topic
----

This command creates the KameletBinding in the current namespace on the cluster.

== Kamelet source file

https://github.com/openshift-integration/kamelet-catalog/blob/main/kafka-batch-source.kamelet.yaml

// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT
