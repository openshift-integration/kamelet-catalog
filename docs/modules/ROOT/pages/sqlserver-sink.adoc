// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT

= image:kamelets/sqlserver-sink.svg[] Microsoft SQL Server Sink

*Provided by: "Red Hat"*

Send data to a Microsoft SQL Server Database.

This Kamelet expects a JSON as body. The mapping between the JSON fields and parameters is done by key, so if you have the following query:

'INSERT INTO accounts (username,city) VALUES (:#username,:#city)'

The Kamelet needs to receive as input something like:

'{ "username":"oscerd", "city":"Rome"}'

== Configuration Options

The following table summarizes the configuration options available for the `sqlserver-sink` Kamelet:
[width="100%",cols="2,^2,3,^2,^2,^3",options="header"]
|===
| Property| Name| Description| Type| Default| Example
| *databaseName {empty}* *| Database Name| The Database Name we are pointing| string| | 
| *password {empty}* *| Password| The password to use for accessing a secured SQL Server Database| string| | 
| *query {empty}* *| Query| The Query to execute against the SQL Server Database| string| | `"INSERT INTO accounts (username,city) VALUES (:#username,:#city)"`
| *serverName {empty}* *| Server Name| Server Name for the data source| string| | `"localhost"`
| *username {empty}* *| Username| The username to use for accessing a secured SQL Server Database| string| | 
| serverPort| Server Port| Server Port for the data source| string| `1433`| 
|===

NOTE: Fields marked with an asterisk ({empty}*) are mandatory.


== Dependencies

At runtime, the `sqlserver-sink Kamelet relies upon the presence of the following dependencies:

- camel:jackson
- camel:kamelet
- camel:sql
- mvn:org.apache.commons:commons-dbcp2:2.7.0
- mvn:com.microsoft.sqlserver:mssql-jdbc:9.2.1.jre11 

== Usage

This section describes how you can use the `sqlserver-sink`.

=== Knative Sink

You can use the `sqlserver-sink` Kamelet as a Knative sink by binding it to a Knative object.

.sqlserver-sink-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1alpha1
kind: KameletBinding
metadata:
  name: sqlserver-sink-binding
spec:
  source:
    ref:
      kind: Channel
      apiVersion: messaging.knative.dev/v1
      name: mychannel
  sink:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1alpha1
      name: sqlserver-sink
    properties:
      databaseName: "The Database Name"
      password: "The Password"
      query: "INSERT INTO accounts (username,city) VALUES (:#username,:#city)"
      serverName: "localhost"
      username: "The Username"
  
----

==== *Prerequisite*

Make sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `sqlserver-sink-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the sink by using the following command:
+
[source,shell]
----
oc apply -f sqlserver-sink-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the sink by using the following command:

[source,shell]
----
kamel bind channel:mychannel sqlserver-sink -p "sink.databaseName=The Database Name" -p "sink.password=The Password" -p "sink.query=INSERT INTO accounts (username,city) VALUES (:#username,:#city)" -p "sink.serverName=localhost" -p "sink.username=The Username"
----

This command creates the KameletBinding in the current namespace on the cluster.

=== Kafka Sink

You can use the `sqlserver-sink` Kamelet as a Kafka sink by binding it to a Kafka topic.

.sqlserver-sink-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1alpha1
kind: KameletBinding
metadata:
  name: sqlserver-sink-binding
spec:
  source:
    ref:
      kind: KafkaTopic
      apiVersion: kafka.strimzi.io/v1beta1
      name: my-topic
  sink:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1alpha1
      name: sqlserver-sink
    properties:
      databaseName: "The Database Name"
      password: "The Password"
      query: "INSERT INTO accounts (username,city) VALUES (:#username,:#city)"
      serverName: "localhost"
      username: "The Username"
  
----

==== *Prerequisites*

Ensure that you've installed the *AMQ Streams* operator in your OpenShift cluster and created a topic named `my-topic` in the current namespace.
Make also sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `sqlserver-sink-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the sink by using the following command:
+
[source,shell]
----
oc apply -f sqlserver-sink-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the sink by using the following command:

[source,shell]
----
kamel bind kafka.strimzi.io/v1beta1:KafkaTopic:my-topic sqlserver-sink -p "sink.databaseName=The Database Name" -p "sink.password=The Password" -p "sink.query=INSERT INTO accounts (username,city) VALUES (:#username,:#city)" -p "sink.serverName=localhost" -p "sink.username=The Username"
----

This command creates the KameletBinding in the current namespace on the cluster.

== Kamelet source file

https://github.com/openshift-integration/kamelet-catalog/blob/main/sqlserver-sink.kamelet.yaml

// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT
