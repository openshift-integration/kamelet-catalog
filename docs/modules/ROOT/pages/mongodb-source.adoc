// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT

= image:kamelets/mongodb-source.svg[] MongoDB Source

*Provided by: "Red Hat"*

Consume documents from MongoDB.

If the persistentTailTracking option will be enabled, the consumer will keep track of the last consumed message and on the next restart, the consumption will restart from that message. In case of persistentTailTracking enabled, the tailTrackIncreasingField must be provided (by default it is optional).

If the persistentTailTracking option won't be enabled, the consumer will consume the whole collection and wait in idle for new documents to consume.

== Configuration Options

The following table summarizes the configuration options available for the `mongodb-source` Kamelet:
[width="100%",cols="2,^2,3,^2,^2,^3",options="header"]
|===
| Property| Name| Description| Type| Default| Example
| *collection {empty}* *| MongoDB Collection| Sets the name of the MongoDB collection to bind to this endpoint.| string| | 
| *database {empty}* *| MongoDB Database| Sets the name of the MongoDB database to target.| string| | 
| *hosts {empty}* *| MongoDB Hosts| Comma separated list of MongoDB Host Addresses in host:port format.| string| | 
| *password {empty}* *| MongoDB Password| User password for accessing MongoDB.| string| | 
| *username {empty}* *| MongoDB Username| Username for accessing MongoDB. The username must be present in the MongoDB's authentication database (authenticationDatabase). By default, the MongoDB authenticationDatabase is 'admin'.| string| | 
| persistentTailTracking| MongoDB Persistent Tail Tracking| Enable persistent tail tracking, which is a mechanism to keep track of the last consumed message across system restarts. The next time the system is up, the endpoint will recover the cursor from the point where it last stopped slurping records.| boolean| `false`| 
| tailTrackIncreasingField| MongoDB Tail Track Increasing Field| Correlation field in the incoming record which is of increasing nature and will be used to position the tailing cursor every time it is generated.| string| | 
|===

NOTE: Fields marked with an asterisk ({empty}*) are mandatory.


== Dependencies

At runtime, the `mongodb-source` Kamelet relies upon the presence of the following dependencies:

- camel:kamelet
- camel:mongodb
- camel:jackson 

== Usage

This section describes how you can use the `mongodb-source`.

=== Knative Source

You can use the `mongodb-source` Kamelet as a Knative source by binding it to a Knative object.

.mongodb-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1alpha1
kind: KameletBinding
metadata:
  name: mongodb-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1alpha1
      name: mongodb-source
    properties:
      collection: "The MongoDB Collection"
      database: "The MongoDB Database"
      hosts: "The MongoDB Hosts"
      password: "The MongoDB Password"
      username: "The MongoDB Username"
  sink:
    ref:
      kind: Channel
      apiVersion: messaging.knative.dev/v1
      name: mychannel
  
----

==== *Prerequisite*

Make sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `mongodb-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f mongodb-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind mongodb-source -p "source.collection=The MongoDB Collection" -p "source.database=The MongoDB Database" -p "source.hosts=The MongoDB Hosts" -p "source.password=The MongoDB Password" -p "source.username=The MongoDB Username" channel:mychannel
----

This command creates the KameletBinding in the current namespace on the cluster.

=== Kafka Source

You can use the `mongodb-source` Kamelet as a Kafka source by binding it to a Kafka topic.

.mongodb-source-binding.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1alpha1
kind: KameletBinding
metadata:
  name: mongodb-source-binding
spec:
  source:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1alpha1
      name: mongodb-source
    properties:
      collection: "The MongoDB Collection"
      database: "The MongoDB Database"
      hosts: "The MongoDB Hosts"
      password: "The MongoDB Password"
      username: "The MongoDB Username"
  sink:
    ref:
      kind: KafkaTopic
      apiVersion: kafka.strimzi.io/v1beta1
      name: my-topic
  
----

==== *Prerequisites*

Ensure that you've installed the *AMQ Streams* operator in your OpenShift cluster and created a topic named `my-topic` in the current namespace.
Make also sure you have *"Red Hat Integration - Camel K"* installed into the OpenShift cluster you're connected to.

==== *Procedure for using the cluster CLI*

. Save the `mongodb-source-binding.yaml` file to your local drive, and then edit it as needed for your configuration.

. Run the source by using the following command:
+
[source,shell]
----
oc apply -f mongodb-source-binding.yaml
----

==== *Procedure for using the Kamel CLI*

Configure and run the source by using the following command:

[source,shell]
----
kamel bind mongodb-source -p "source.collection=The MongoDB Collection" -p "source.database=The MongoDB Database" -p "source.hosts=The MongoDB Hosts" -p "source.password=The MongoDB Password" -p "source.username=The MongoDB Username" kafka.strimzi.io/v1beta1:KafkaTopic:my-topic
----

This command creates the KameletBinding in the current namespace on the cluster.

== Kamelet source file

https://github.com/openshift-integration/kamelet-catalog/blob/main/mongodb-source.kamelet.yaml

// THIS FILE IS AUTOMATICALLY GENERATED: DO NOT EDIT
